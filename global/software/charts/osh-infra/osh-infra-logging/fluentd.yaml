---
schema: armada/Chart/v1
metadata:
  schema: metadata/Document/v1
  name: fluentd
  layeringDefinition:
    abstract: false
    layer: global
  labels:
    hosttype: fluentd-global
  storagePolicy: cleartext
  substitutions:
    # Chart source
    - src:
        schema: pegleg/SoftwareVersions/v1
        name: software-versions
        path: .charts.osh_infra.fluentd
      dest:
        path: .source

    # Images
    - src:
        schema: pegleg/SoftwareVersions/v1
        name: software-versions
        path: .images.osh_infra.fluentd
      dest:
        path: .values.images.tags

    # Endpoints
    - src:
        schema: pegleg/EndpointCatalogue/v1
        name: osh_infra_endpoints
        path: .osh_infra.elasticsearch
      dest:
        path: .values.endpoints.elasticsearch
    - src:
        schema: pegleg/EndpointCatalogue/v1
        name: osh_infra_endpoints
        path: .osh_infra.fluentd
      dest:
        path: .values.endpoints.fluentd
    - src:
        schema: pegleg/EndpointCatalogue/v1
        name: osh_infra_endpoints
        path: .osh_infra.prometheus_fluentd_exporter
      dest:
        path: .values.endpoints.prometheus_fluentd_exporter
    - src:
        schema: pegleg/EndpointCatalogue/v1
        name: osh_infra_endpoints
        path: .osh_infra.kafka
      dest:
        path: .values.endpoints.kafka
    # Accounts
    - src:
        schema: pegleg/AccountCatalogue/v1
        name: osh_infra_service_accounts
        path: .osh_infra.elasticsearch.admin
      dest:
        path: .values.endpoints.elasticsearch.auth.admin

    # Secrets
    - dest:
        path: .values.endpoints.elasticsearch.auth.admin.password
      src:
        schema: deckhand/Passphrase/v1
        name: osh_infra_elasticsearch_admin_password
        path: .

    # DMaaP Mech ID Details
    - src:
        schema: pegleg/AccountCatalogue/v1
        name: osh_infra_service_accounts
        path: .osh_infra.kafka.admin
      dest:
        path: .values.endpoints.kafka.auth.admin
    - dest:
        path: .values.endpoints.kafka.auth.admin.password
      src:
        schema: deckhand/Passphrase/v1
        name: osh_infra_dmaap_mechid_password
        path: .
    # DMaaP Topic
    - src:
        schema: nc/CorridorConfig/v1
        name: corridor-config
        path: .infrastructure.dmaap.namespace
      dest:
        path: .values.pod.env.fluentd.vars.TOPIC
        pattern: NAMESPACE
    - src:
        schema: nc/CorridorConfig/v1
        name: corridor-config
        path: .infrastructure.dmaap.topic
      dest:
        path: .values.pod.env.fluentd.vars.TOPIC
        pattern: DMAAP_TOPIC

data:
  chart_name: fluentd
  release: fluentd
  namespace: osh-infra
  wait:
    timeout: 900
    labels:
      release_group: clcp-fluentd
    # TODO: Re-enable pod waiting once [NCEI-171] is fixed.
    resources:
      - type: daemonset
  install:
    no_hooks: false
  upgrade:
    no_hooks: false
    options:
      force: true
      # TODO: This is just to get label updates in place for NC 1.6, unwind in
      # 1.7.
    pre:
      delete:
        - type: job
          labels:
            release_group: clcp-fluentd
      create: []
    post:
      create: []
  values:
    manifests:
      secret_kafka: true
    deployment:
      type: DaemonSet
    monitoring:
      prometheus:
        enabled: true
    pod:
      env:
        fluentd:
          vars:
            TOPIC: NAMESPACE.DMAAP_TOPIC
      security_context:
        fluentd:
          pod:
            runAsUser: 0
      apparmor:
        fluentd:
          fluentd: localhost/docker-default
          init: localhost/docker-default
      resources:
        enabled: true
        fluentd:
          limits:
            memory: '8Gi'
            cpu: '2000m'
          requests:
            memory: '4Gi'
            cpu: '1000m'
        prometheus_fluentd_exporter:
          limits:
            memory: '1024Mi'
            cpu: '2000m'
          requests:
            memory: '0'
            cpu: '0'
        jobs:
          image_repo_sync:
            requests:
              memory: '0'
              cpu: '0'
            limits:
              memory: '1024Mi'
              cpu: '2000m'
          tests:
            requests:
              memory: '0'
              cpu: '0'
            limits:
              memory: '1024Mi'
              cpu: '2000m'
      lifecycle:
        upgrades:
          daemonsets:
            fluentd:
              max_unavailable: 100%
    labels:
      fluentd:
        node_selector_key: fluentd
        node_selector_value: enabled
      prometheus_fluentd_exporter:
        node_selector_key: openstack-control-plane
        node_selector_value: enabled
      job:
        node_selector_key: openstack-control-plane
        node_selector_value: enabled
      test:
        node_selector_key: openstack-control-plane
        node_selector_value: enabled
    conf:
      fluentd:
        template: |
          <source>
            bind 0.0.0.0
            port 24220
            @type monitor_agent
          </source>

          <source>
            bind 0.0.0.0
            port "#{ENV['FLUENTD_PORT']}"
            @type forward
          </source>

          <match fluent.**>
            @type null
          </match>

          <source>
            <parse>
              @type regexp
              expression /^(?<time>.+) (?<stream>stdout|stderr)( (?<logtag>.))? (?<log>.*)$/
              time_format '%Y-%m-%dT%H:%M:%S.%N%:z'
              keep_time_key false
            </parse>
            path /var/log/containers/*.log
            pos_file /var/log/containers/fd.containers.log.pos
            read_from_head true
            tag kubernetes.*
            @type tail
          </source>

          <source>
            @type tail
            tag ceph.*
            path /var/log/ceph/clcp-ucp-ceph-mon/*.log
            pos_file /var/log/ceph/clcp-ucp-ceph-mon/fd.clcp-ucp-ceph-mon.log.pos
            read_from_head true
            <parse>
              @type none
            </parse>
          </source>

          <source>
            @type tail
            tag ceph.*
            path /var/log/ceph/clcp-ucp-ceph-osd/ceph-osd**.log
            pos_file /var/log/ceph/clcp-ucp-ceph-osd/fd.ceph-osd.log.pos
            read_from_head true
            <parse>
              @type none
            </parse>
          </source>

          <source>
            @type tail
            tag tenant-ceph.*
            path /var/log/ceph/clcp-tenant-ceph-mon/*.log
            pos_file /var/log/ceph/clcp-tenant-ceph-mon/fd.clcp-tenant-ceph-mon.log.pos
            read_from_head true
            <parse>
              @type none
            </parse>
          </source>

          <source>
            @type tail
            tag tenant-ceph.*
            path /var/log/ceph/clcp-tenant-ceph-osd/ceph-osd**.log
            pos_file /var/log/ceph/clcp-tenant-ceph-osd/fd.ceph-osd.log.pos
            read_from_head true
            <parse>
              @type none
            </parse>
          </source>

          <source>
            @type tail
            tag auth
            path /var/log/auth.log
            pos_file /var/log/fd.auth.log.pos
            read_from_head true
            <parse>
              @type none
            </parse>
          </source>

          <source>
            @type tail
            tag libvirt
            path /var/log/libvirt/libvirtd.log
            pos_file /var/log/libvirt/fd.libvirtd.log.pos
            read_from_head true
            <parse>
              @type none
            </parse>
          </source>

          <source>
            @type tail
            tag qemu
            path /var/log/libvirt/qemu/*.log
            pos_file /var/log/libvirt/fd.qemu.log.pos
            read_from_head true
            <parse>
              @type none
            </parse>
          </source>

          <source>
            @type tail
            tag kernel
            path /var/log/kern.log
            pos_file /var/log/fd.kern.log.pos
            read_from_head true
            <parse>
              @type none
            </parse>
          </source>

          <source>
            @type tail
            tag flows
            path /var/log/calico/flowlogs/flows.log
            pos_file /var/log/calico/flowlogs/fd.flows.log.pos
            read_from_head true
            <parse>
              @type none
            </parse>
          </source>

          <source>
            @type systemd
            tag journal.*
            path /var/log/journal
            pos_file /var/log/fd.journal.pos
            matches [{ "_SYSTEMD_UNIT": "kubelet.service" }]
            read_from_head true
            <entry>
              fields_strip_underscores true
              fields_lowercase true
            </entry>
          </source>

          <source>
            @type systemd
            tag dmesg
            path /var/log/journal
            pos_file /var/log/fd.journal.pos
            matches [{ "_TRANSPORT": "kernel" }]
            read_from_head true
            <entry>
              fields_strip_underscores true
              fields_lowercase true
            </entry>
          </source>

          <source>
            @type tail
            tag syslog
            path /var/log/syslog
            pos_file /var/log/fd.syslog.pos
            read_from_head true
            <parse>
              @type none
            </parse>
          </source>

          <source>
            @type tail
            tag audit-tsee
            path /var/log/calico/audit/tsee-audit.log
            pos_file /var/log/calico/audit/fd.tsee-audit.log.pos
            read_from_head true
            <parse>
              @type none
            </parse>
          </source>


          <filter kubernetes.**>
            @type kubernetes_metadata
          </filter>

          <filter ceph.**>
            @type record_transformer
            <record>
              hostname "#{ENV['NODE_NAME']}"
              fluentd_pod "#{ENV['POD_NAME']}"
            </record>
          </filter>

          <filter tenant-ceph.**>
            @type record_transformer
            <record>
              hostname "#{ENV['NODE_NAME']}"
              fluentd_pod "#{ENV['POD_NAME']}"
            </record>
          </filter>

          <filter libvirt>
            @type record_transformer
            <record>
              hostname "#{ENV['NODE_NAME']}"
              fluentd_pod "#{ENV['POD_NAME']}"
            </record>
          </filter>

          <filter qemu>
            @type record_transformer
            <record>
              hostname "#{ENV['NODE_NAME']}"
              fluentd_pod "#{ENV['POD_NAME']}"
            </record>
          </filter>

          <filter kernel>
            @type record_transformer
            <record>
              hostname "#{ENV['NODE_NAME']}"
              fluentd_pod "#{ENV['POD_NAME']}"
            </record>
          </filter>

          <filter auth>
            @type record_transformer
            <record>
              hostname "#{ENV['NODE_NAME']}"
              fluentd_pod "#{ENV['POD_NAME']}"
            </record>
          </filter>

          <filter syslog>
            @type record_transformer
            <record>
              hostname "#{ENV['NODE_NAME']}"
              fluentd_pod "#{ENV['POD_NAME']}"
            </record>
          </filter>

          <filter flows>
            @type record_transformer
            <record>
              hostname "#{ENV['NODE_NAME']}"
              fluentd_pod "#{ENV['POD_NAME']}"
              topic "#{ENV['TOPIC']}"
              partition_key_key "calico-flows"
            </record>
          </filter>

          <filter audit-tsee>
            @type record_transformer
            <record>
              hostname "#{ENV['NODE_NAME']}"
              fluentd_pod "#{ENV['POD_NAME']}"
            </record>
          </filter>

          <match libvirt>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix libvirt
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match qemu>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix libvirt
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match flows>
            @type copy
            <store>
              @type kafka2
              get_kafka_client_log true
              brokers "#{ENV['KAFKA_BROKER']}"
              use_event_time true
              username "#{ENV['KAFKA_USERNAME']}"
              password "#{ENV['KAFKA_PASSWORD']}"
              sasl_over_ssl false
              <format>
                @type json
              </format>
              topic_key topic
              max_send_limit_bytes 1000000
              <buffer topic>
                chunk_limit_size 2MB
                disable_chunk_backup true
                queue_limit_length 2048
                flush_interval 5s
                flush_thread_count 8
                overflow_action drop_oldest_chunk
                retry_forever false
                retry_max_interval 1h
                retry_timeout 30s
                retry_wait 5
              </buffer>
            </store>
            <store>
              <buffer>
                chunk_limit_size 2MB
                queue_limit_length 2048
                flush_interval 5s
                flush_thread_count 2
                retry_forever true
                retry_max_interval 1h
                retry_wait 5
              </buffer>
              host "#{ENV['ELASTICSEARCH_HOST']}"
              include_tag_key true
              logstash_format true
              logstash_prefix flows
              password "#{ENV['ELASTICSEARCH_PASSWORD']}"
              port "#{ENV['ELASTICSEARCH_PORT']}"
              reconnect_on_error true
              reload_connections false
              reload_on_failure true
              @type elasticsearch
              user "#{ENV['ELASTICSEARCH_USERNAME']}"
            </store>
          </match>

          <match journal.**>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix journal
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kernel>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix kernel_syslog
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match syslog.**>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix kernel_syslog
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match auth>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix auth
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match dmesg>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix journal
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match audit-tsee>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix audit_tsee
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.clcp-**-utility**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix utility_access
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match ceph.**>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix ceph
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match tenant-ceph.**>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix ceph
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.openvswitch-**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix openvswitch
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match **.shipyard-**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix airship
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match **.armada-**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix airship
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match **.horizon-**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix openstack
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match **.calico-**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix calico
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match **.ranger-**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix openstack
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match **.ro-**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix openstack
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match **.jenkins-**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix jenkins
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.keystone**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix openstack
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.glance**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix openstack
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.nova**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix openstack
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.cinder**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix openstack
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.neutron-server**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix openstack
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.neutron**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix openstack
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.heat**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix openstack
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.grafana**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix lma
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.prometheus**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix lma
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.kibana**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix lma
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.elasticsearch**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix lma
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match kubernetes.var.log.containers.nagios**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            logstash_prefix lma
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>

          <match **.kubernetes.**.log>
            <buffer>
              chunk_limit_size 2MB
              queue_limit_length 2048
              flush_interval 5s
              flush_thread_count 2
              retry_forever true
              retry_max_interval 1h
              retry_wait 5
            </buffer>
            host "#{ENV['ELASTICSEARCH_HOST']}"
            include_tag_key true
            logstash_format true
            password "#{ENV['ELASTICSEARCH_PASSWORD']}"
            port "#{ENV['ELASTICSEARCH_PORT']}"
            reconnect_on_error true
            reload_connections false
            reload_on_failure true
            @type elasticsearch
            user "#{ENV['ELASTICSEARCH_USERNAME']}"
          </match>
      fluentd_exporter:
        log:
          format: "logger:stdout?json=true"
          level: "info"
  dependencies:
    - fluentd-htk
...
---
schema: armada/Chart/v1
metadata:
  schema: metadata/Document/v1
  name: fluentd-htk
  layeringDefinition:
    abstract: false
    layer: global
  substitutions:
    - src:
        schema: pegleg/SoftwareVersions/v1
        name: software-versions
        path: .charts.osh_infra.fluentd-htk
      dest:
        path: .source
  storagePolicy: cleartext
data:
  chart_name: fluentd-htk
  release: fluentd-htk
  namespace: fluentd-htk
  timeout: 600
  wait:
    timeout: 600
  upgrade:
    no_hooks: true
  values: {}
  dependencies: []
...
